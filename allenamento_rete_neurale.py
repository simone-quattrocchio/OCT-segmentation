# -*- coding: utf-8 -*-
"""Allenamento_rete_neurale.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NWNF2UyJFquEX1Xl1S13sDOtYQzoNS3Y

**SINCRONIZZAZIONE CON GOOGLE DRIVE**
"""

from google.colab import drive
drive.mount('/content/drive')

"""**IMPORTAZIONE DELLE LIBRERIE NECESSARIE**"""

from PIL import Image
import os
import numpy as np
import matplotlib.pyplot as plt
import cv2
from scipy import ndimage
from skimage import exposure
from tqdm import tqdm
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import albumentations as A
from albumentations.pytorch import ToTensorV2
from skimage.transform import resize

"""**DEFINIZIONE TRASFORMAZIONI PER DATA AUGMENTATION**

Vengono definite con l'uso della libreria albumentation ( https://albumentations.ai/docs/) le trasformazioni applicate sul train set e validation set.

*Train set* :
1.  Resize dalle dimensioni originali 800x1200 a 512x512; questo è necessario in quanto la rete non sarebbe in grado di processare immagini di dimensioni non quadrate e con la grandezza originale.
2. Cambiameto del contrasto con probabilità del 20%.
3. Gamma correction con probabilità del 50%.
4. Trasformazione in tensore, necessaria per l'elaborazione in Pytorch.

*Validation e test set*:
1.   Resize dalle dimensioni originali 800x1200 a 512x512 per le stesse ragioni del train set.
2.   Trasformazione in tensore, stesse ragioni del train set.




"""

import albumentations as A
from albumentations.pytorch import ToTensorV2

# Augmentation per training set

aug = A.Compose([
    A.Resize(width=512, height=512),
    A.RandomBrightnessContrast(p=0.2),
    A.RandomGamma(p=0.5),

    ToTensorV2()
])
# Augmentation per validation e test set

transform_val_test = A.Compose([
    A.Resize(512,512),
    ToTensorV2()

])

"""**DEFINIZIONE CLASSE OCT**

In questa sezione viene creata la classe OCT, una classe che eredita dalla classe Dataset di Pythorch le sue proprietà; la sua funzione è quella di generare una tupla con il batch di immagini e le corrispondenti maschere con cui è possibile impostare l'allenamento in maniera iterativa.

Le immagini vengono inoltre normalizzate in float, andando a dividere per la dinamica su 8 bit in cui erano state salvate, viene fatto un clipping tra 0 e 1 ,viene assicurata che l'immagine sia codificata su tre canali (RGB)

*Input*:
1.   Percorso alla cartella delle immagini.
2.   Percorso alla cartella delle immagini.
3. Eventuale traformazione (vedi Data Augmentation)

*Output*:
1.   Tupla contenente immagine e maschera.

*Errori*:
1.  Quando i nomi di maschera ad immagine non corrrispondono viene esplicitato un Assertion Error.








"""

class OCT(Dataset):
    """
    Un dataset di Pytorch per caricare immagini e le maschere corrispondenti

   INPUT:
        image_paths (lista):Una lista contenente il percorso alla cartella delle immagini.
        mask_paths (lista): Una lista contenente il percorso alla cartella delle maschere corrispondenti..
        transform (opzionale, richiamabile): Una funzione trasformazione che dalle immagini PIL genera la loro versione trasformata.
            E.g, ``transforms.RandomCrop``

    Output:
        tuple: Una tupla contenente immagine e le maschere corrispondenti.

    Raises:
        AssertionError: Viene generato un avviso di errore se il nome del file di
         maschere e immagini non corrispondono, se hanno dimensioni diverse, se sono in un formato diverso dal float32, se non sono tensori  o se le maschere contengono valori non binari (0 o 1)

    """
    # La funzione __init__  è eseguita una volta sola per inizializzare il dataset usando la classe UltrasoundDataset
    def __init__(self, image_paths, mask_paths, transform=None):
        self.image_paths = image_paths  #dir to folder of images and masks
        self.mask_paths = mask_paths
        self.transform = transform
        self.images=os.listdir(image_paths)
        self.masks=os.listdir(mask_paths)

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):

        image_path =os.path.join( self.image_paths,self.images[idx])
        mask_path = os.path.join( self.mask_paths,self.masks[idx])

        #Conttrollo sulla coerenza del nome
        assert image_path.split('/')[-1].split('.')[0] == mask_path.split('/')[-1].split('.')[0], "Filename mismatch between image and mask!"

        # apertura immagine e conversione in scala di grigio ('L'), float32 e numpy array
        image = np.array(Image.open(image_path).convert('RGB'),dtype=np.float32)
        mask = np.array(Image.open(mask_path).convert('L'),dtype=np.float32)

        #Normalizzazione dell' immagine da codifica su 8bit a float compresa tra 0 e 1 , viene inoltre fatto un clipping per assicurare che non ci siano valori minori di 0 o maggiori di 1.

        image = image / 255
        image[image < 0] = 0
        image[image > 1] = 1

        # Conversione della maschera da codifica a 8bit in booleana (True,False)
        mask =(mask > 0).astype(np.float32)

        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image = augmented['image']
            mask = augmented['mask']

        # Controllo che l'input relativo al canale colore sia 3, per garantire versatilità al codice di processare anche immagini RGB,
        # nel caso esse si abbiano immagini in bianco e nero il singolo canale viene concatenato in modo tale da avere dimensione pari a 3.

        if image.shape[0] == 1:
            image = torch.cat((image, image, image), dim=0)

        # Trasformazione in tensore
        if type(image) == np.ndarray:
            image = torch.from_numpy(image)

        # Ulteriore cast in float32 e tensore di maschera e immagine

        torch.as_tensor(image,dtype=torch.float32)
        mask = torch.as_tensor(mask, dtype=torch.float32)

        # Controllo sulle dimensioni
        assert image.size(-1) == mask.size(-1), f"Image ({image.size()}) and mask ({mask.size()}) have different last two dimensions!"

        # Controllo sulla binarietà maschera
        assert torch.all(torch.logical_or(mask == 0, mask == 1)), f"Mask has values other than 0 and 1!"

        # Controllo sul tipo float32
        assert image.dtype == torch.float32, f"Image dtype {image.dtype} is not torch.float32!"
        assert mask.dtype == torch.float32, f"Mask dtype {mask.dtype} is not torch.float32!"

        # Salvataggio del nome
        file_name = image_path.split('/')[-1].split('.')[0]

        return image, mask, file_name

"""**PREPARAZIONE DATASET**

Viene usata la classe OCT definita in precedenza indicando i percorsi corrispondenti al train,val e test set, applicando le corrette trasformazioni.

E' impostato qui il batch size a 4

Inoltre viene richiamata la funzione Dataloader, che dato in input la tupla ottenuta con la classe OCT restituisce un oggetto iterabile  gestendo la logica di suddivisione del dataset in batch ed  il mescolamento dei dati;

Si è impostato shuffle = True per il train in modo che alla rete vengano presentate le immagini in maniera sempre diversa e acquisisca maggiori capacità
di generalizzazione.

"""

# Definizione dei path alle cartelle corrette
working_folder ='/content/drive/MyDrive/Challenge'
image_folder=os.path.join(working_folder,'DatasetProc/volumes')
mask_folder=os.path.join(working_folder,'DatasetProc/masks')

# Applicazione della classe OCT
train_dataset = OCT(os.path.join(image_folder,'train'), os.path.join(mask_folder,'train'), transform=aug)
val_dataset = OCT(os.path.join(image_folder,'val'), os.path.join(mask_folder,'val'), transform=transform_val_test)
test_dataset = OCT(os.path.join(image_folder,'test'), os.path.join(mask_folder,'test'), transform=transform_val_test)

# Definizione Batch Size
BS =4

# Dataloader permette di creare un oggetto iterabile nell'allenamento
train_loader = DataLoader(train_dataset, BS, shuffle=True)
val_loader = DataLoader(val_dataset,BS, shuffle=False)

"""**VERIFICA ACCOPPIAMENTO IMMAGINI E MASCHERE**




Plot di verifica che l'accopiamento tra maschere e immagini sia coerente; vengono presentati un batch di train e validation rispettivamente.
"""

# Viene preso un batch di immagini e le relative maschere da train e validation
# le immagini sono poi plottate su colormap in scala di grigio e ad esse sovrapposte
# le maschere in colormap 'jet' con due tonalità diverse per train e val set.

# Train set

images, masks, filename = next(iter(train_loader))
plt.figure(figsize=(10, 10))
for i in range(BS):
    plt.subplot(BS, BS, i + 1)
    plt.imshow(images[i, 0].numpy(), cmap='gray')
    plt.imshow(masks[i].numpy(), cmap='jet', alpha=0.7)
    plt.axis('off')
plt.tight_layout()
plt.show()

# Val set

images, masks, filename = next(iter(val_loader))
plt.figure(figsize=(10, 10))
for i in range(BS):
    plt.subplot(BS, BS, i + 1)
    plt.imshow(images[i, 0].numpy(), cmap='gray')
    plt.imshow(masks[i].numpy(), cmap='jet', alpha=0.5)
    plt.axis('off')
plt.tight_layout()
plt.show()

"""**RETE CONVOLUZIONALE**

Si definisce l'architettura della rete come sottoclasse di nn.Module; nel metodo forward sono definite le operazioni  di ogni layer della rete, esso accetta un tensore x rappresentante l'immagine in input e restituisce un tensore che rappresenta l'output della rete.

La rete è composta da:

Un "Contracting path" che riduce gradualmente la risoluzione dell'immagine attraverso una serie di blocchi convoluzionali e di max pooling.
Un "Lowest resolution" che rappresenta il livello con la risoluzione più bassa dell'immagine.
Un "Expansive path" che ricostruisce l'immagine ad alta risoluzione a partire dai feature maps del "Lowest resolution" utilizzando operazioni di up-convolution e concatenazioni con i feature maps dei layer corrispondenti della "Contracting path".
I principali parametri della rete sono:

input_channels: Il numero di canali dell'immagine in ingresso.

out_classes: Il numero di classi di output della rete.
Il metodo forward accetta un tensore x rappresentante l'immagine in input e restituisce un tensore che rappresenta l'output della rete.

Il tensore di output ha le dimensioni (batch_size, out_classes, M,N) dove batch_size è la dimensione del batch, out_classes è il numero di classi di output della rete, e M,N sono le dimensioni dell'immagine.

Infine è presente una prova per controllare le corrette dimensioni dell'output.
"""

import torch
import torch.nn as nn

class UNet(nn.Module):
    def __init__(self, input_channels=3, out_classes=1):
        super(UNet, self).__init__()

        # Contracting path
        self.enc1 = self.conv_block(input_channels,32)
        self.enc2 = self.conv_block(32, 64)
        self.enc3 = self.conv_block(64, 128)
        self.enc4 = self.conv_block(128, 256)

        self.pool = nn.MaxPool2d(kernel_size=2)

        # Bottleneck, minima risoluzione
        self.bottleneck = self.conv_block(256, 512)

        # Expansive path
        self.upconv4=nn.ConvTranspose2d(512,256, kernel_size=2, stride=2)
        self.dec4 = self.conv_block(512, 256)
        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.dec3 = self.conv_block(384, 128)
        self.upconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.dec2 = self.conv_block(256, 64)
        self.upconv1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)
        self.dec1 = self.conv_block(160, 32)

        self.out = nn.Conv2d(32, out_classes, kernel_size=1)

    def conv_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),

            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
        )

    def forward(self, x):
        # Contracting path
        x1 = self.enc1(x)
        x2 = self.enc2(self.pool(x1))
        x3 = self.enc3(self.pool(x2))
        x4 = self.enc4(self.pool(x3))

        # Lowest resolution
        x5 = self.bottleneck(self.pool(x4))
        x5=self.upconv4(x5)

        # Expansive path
        x = torch.cat([x4, x5], dim=1)
        x = self.dec4(x)
        x = self.upconv3(x)

        x21=self.upconv3(x4)
        x = torch.cat([x3, x, x21], dim=1)
        x = self.dec3(x)
        x = self.upconv2(x)

        x11=self.upconv2(x3)
        x12=self.upconv2(x21)
        x = torch.cat([x2, x, x11,x12], dim=1)
        x = self.dec2(x)
        x = self.upconv1(x)

        x01=self.upconv1(x2)
        x02=self.upconv1(x11)
        x03=self.upconv1(x12)
        x = torch.cat([x1, x, x01,x02,x03], dim=1)
        x = self.dec1(x)

        x = self.out(x)
        return x

# Prova di esempio
H = 128
W = 128
C = 3
batch_size = 4
X_batch = torch.randn((batch_size, C, H, W))
model=UNet()
output_batch = model(X_batch)
print("Output batch shape:", output_batch.shape)

"""**DEFINIZIONE LOSS FUNCTION, OTTIMIZZATORE E SCHEDULER**

In questo blocco si definiscono le funzioni di loss utilizzabili nell' allenamento, rispettivamente Dice Loss e binary cross entropy.

DICE LOSS:

La formula del Dice Loss è una metrica basata sul coefficiente di Dice, che valuta la similarità tra due insiemi. In questo caso, viene calcolata la perdita complementare al coefficiente di Dice, in modo che una perdita più bassa corrisponda a una maggiore similarità tra le predizioni e le etichette

BCE Loss:
La funzione di loss Binary Cross Entropy (BCE) implementata da  PyTorch, calcola la perdita tra le probabilità predette dal modello e le etichette binarie.

E' presente un esempio per accertarsi della correttezza dell' implementazione.

E' stato impostato dalla libreria di Pytorch l' ottimizzatore Adam, esso ha la funzione di aggiornare i pesi del modello durante l'addestramento, e si imposta il leraning rate a 0.0005.

Infine si imposta lo scheduler per regolare dinamicamente il tasso di apprendimento durante l'addestramento, monitorando la funzione di loss.

"""

from torch.optim import Adam
from torch.optim.lr_scheduler import ReduceLROnPlateau
import torch.nn.functional as F

# Dice loss.
def dice_loss(outputs, labels, eps=1e-7):
    intersection = torch.sum(outputs * labels)
    union = torch.sum(outputs) + torch.sum(labels)
    dice_score = 2.0 * intersection / (union + eps)
    weighted_dice_loss = 1.0 - dice_score

    return weighted_dice_loss

# Test Dice Loss
outputs = torch.tensor([[[[0.1, 0.2], [0.3, 0.4]]]])
labels = torch.tensor([[[[0.0, 1.0], [1.0, 0.0]]]])
print(f"Dice Loss: {dice_loss(outputs, labels):.4f}")

# BCE loss
def bce_loss(outputs, labels):
    loss = F.binary_cross_entropy_with_logits(outputs, labels, reduction='mean')

    return loss

# Test BCE Loss
outputs = torch.tensor([[[[0.1, 0.2], [0.3, 0.4]]]])
labels = torch.tensor([[[[0.0, 1.0], [1.0, 0.0]]]])
print(f"BCE Loss: {bce_loss(outputs, labels):.4f}")


# Scelta del criterio di loss da utilizzare
criterion = bce_loss

# Optimizer
optimizer = Adam(model.parameters(), lr=0.0005)

# Learning rate scheduler
scheduler = ReduceLROnPlateau(optimizer, 'min')

"""**DEFINIZIONE METRICHE VALUTAZIONE**

Vengono definite alcune metriche di valutazione per giudicare la qualità della segmentazione

*Intersection over union*:

Viene computato l IOU tra le maschere predette dal modello e le maschere di ground truth, viene restituito un valore compreso tra 0 e 1, dove 1 corrisponde a una perfetta sovrapposizione tra le maschere.

*Dice coefficient*:

Calcola il coefficiente di Dice tra le maschere predette dal modello e le maschere di ground truth, restituisce un valore compreso tra 0 e 1, dove 1 corrisponde a una perfetta corrispondenza tra le maschere.
"""

def IOU(outputs, labels):
    """
    Calcolo della IOU delle immagini sia nel caso siano numpy che tensori
    """

    # Conversione da tensore a numpy se necessario
    if isinstance(outputs, torch.Tensor):
        outputs = outputs.detach().cpu().numpy()
    if isinstance(labels, torch.Tensor):
        labels = labels.detach().cpu().numpy()

    # Controllo sulla dimensione di predizione di maschere e predizioni
    if len(labels.shape) == len(outputs.shape) - 1:
        labels = np.expand_dims(labels, axis=1)

    # Conversione delle labels in booleane
    labels = labels.astype(bool)

    # Applicazione della soglia per fare inferenza
    outputs = outputs > 0.5

    # Calcolo della IOU
    intersection = np.logical_and(labels, outputs)
    union = np.logical_or(labels, outputs)
    iou = np.sum(intersection) / np.sum(union)

    return iou

# Test IOU function
outputs = torch.tensor([[[[0.1, 0.2], [0.6, 0.4]]]])
labels = torch.tensor([[[[0.0, 1.0], [1.0, 0.0]]]])
print(f"IOU: {IOU(outputs, labels):.4f}")


# Dice coefficient metric
def calculate_dsc(mask_manual, mask_auto):
    intersection = np.sum(np.logical_and(mask_manual, mask_auto))
    union = np.sum(np.logical_or(mask_manual, mask_auto))

    dsc = (2.0 * intersection) / ((union + intersection+1e-7))
    return dsc

"""**FUNZIONE PER IL CONTEGGIO DEGLI ORGANOIDI**

In questo blocco si difenisce la funzione per l'impilamento dei volumi necessario al calcolo successivo del numero di organoidi,viene preso in input il nome del file, un elenco di nomi dei volumi di allenamento (nomi_volumi_train), due array volumi_pred e volumi_manual utilizzati per immagazzinare le maschere predette e manuali rispettivamente. La funzione scorre i nomi dei file, estrae le informazioni desiderate dai nomi dei file, come il numero di slice e il tipo di volume, quindi impila le maschere predette e manuali corrispondenti ai volumi di allenamento in base al numero di slice.

Si definisce inoltre la funzione per il calcolo del numero di organoidi dando in input le maschere binarie e contando le label create dalla funzione measure.label che valuta la connettività tridimensionale dei pixels, etichettando le regioni connesse nelle maschere binarie e restituendo sia le maschere etichettate che il numero totale di organoidi trovati.

Vengono infine inizializzate le variabili per tenere traccia di numero di organoidi,labels e errori di conteggio.
"""

from scipy.ndimage import label, generate_binary_structure

# Definizione nomi e numero dei volumi
nomi_volumi_train=['d3_p1_w2','w2_d7','w2_d9','w2_d11','w2_d13','w6_d7','w6_d9']
nomi_volumi_val=['w6_d5','w6_d11']

num_volumes=len(nomi_volumi_train)
num_volumes_val=len(nomi_volumi_val)

def stack_volumi(filename,nomi_volumi, volumi_pred, volumi_manual):
  '''
  Funzione che ricostruisce i volumi posizionando le immagini di predizione e manuali nelle rispettive posizioni all'interno dei volumi iterativamente.
  Viene preso un insieme di nomi di file, viene identificata la corrispondente posizione
  all'interno di volumi specificati, e vengono popolate le matrici 3D con le immagini di predizione e manuali.

  Input:
    - filename: lista di stringhe contenenti i nomi dei file delle immagini/maschere da processare. es. {w2_d5_138, d3_p1_w2_444, w6_d9_1, w6_d9_101}
    - nomi_volumi: lista di stringhe contenenti i nomi dei volumi di riferimento.
    - volumi_pred: lista di array 3D (volumi) inizialmente vuoti, che verranno popolati con le maschere di predizione.
    - volumi_manual: lista di array 3D (volumi) inizialmente vuoti, che verranno popolati con le maschere manuali.

    Output:
    - Restituisce una lista contenente due elementi:
      1. volumi_pred: lista di array 3D popolati con le maschere di predizione.
      2. volumi_manual: lista di array 3D popolati con le maschere manuali.
  '''

  threshold = 0.5  # Valore di soglia, necessario per il processo di inferenza e la ricostruzione di maschere di predizione binarie

  for i in range(0,len(filename)):
    # Viene diviso il testo di ogni elemento della lista filename, per estrarre la posizione in cui collocare la sclice corrispondente
    parts = filename[i].split('_')
    parametro1 = parts[0]  # es.'w2'
    parametro2 = parts[1]  # es.'d5'
    parametro3 = parts[2]  # numero
    # L'if seguente in quanto è presente un volume che restituisce quattro parti quando viene diviso il testo (d1_p1_w2)
    if len(parts)==4:
      tupla_principale = f"{parametro1}_{parametro2}_{parametro3}" #es. d1_p1_w2
      numero=int(parts[3])
    else:
      tupla_principale = f"{parametro1}_{parametro2}" #es. w2_d5
      numero = int(parametro3)

    # Questo for controlla a quale volume appartiene la sclice
    for j in range(0,len(nomi_volumi)):
      if tupla_principale == nomi_volumi[j]:
        #
         imm=outputs[i,:,:].detach().cpu().numpy()>threshold
         volumi_pred[j][numero-1, :, :] = imm
         imm=masks[i,:,:].detach().cpu().numpy()
         volumi_manual[j][numero-1, :, :] = imm
  return [volumi_pred,volumi_manual]

def count_organoids_3d(stacked_masks):
  SE=generate_binary_structure(3,3)
  labeled_org, num_org = label(stacked_masks,SE)

  return labeled_org, num_org
# Inizializzazione delle variabili per il conteggio delle cellule e relativi errori
num_organoids_pred=np.zeros([1,8])
num_organoids_manual=np.zeros([1,8])
num_organoids_pred_val=np.zeros([1,2])
num_organoids_manual_val=np.zeros([1,2])
labeled_organoids_pred=np.zeros([1,8])
labeled_organoids_manual=np.zeros([1,8])
diff=np.zeros([1,8])
diff_val=np.zeros([1,2])
err=np.zeros([1,8])
err_val=np.zeros([1,2])

"""**TRAINING inizializzazione**

In questo blocco vengono impostati gli iperparametri e le variabili necessarie per l'allenamento del modello, inclusi i criteri per l'early stopping basato sul mancato miglioramento della loss dopo 5 epoche., la configurazione del dispositivo e la gestione dei checkpoint.
"""

# Inizializzazione epoche massime di allenamento e variabile per valutazione criterio per early stop
n_epochs = 20
counter=0
patience=5

# Preparazione del device in modalità GPU per allenamento
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

#Creazione delle cartelle per salvataggio dei grafici loss e salvataggio checkpoint

loss_dir=os.path.join(working_folder,"losses")
if not os.path.exists(loss_dir):
    os.makedirs(loss_dir)
checkpoint_dir = os.path.join(working_folder, 'checkpoints')
if not os.path.exists(checkpoint_dir):
    os.makedirs(checkpoint_dir)

# Inizializzazione valori di loss e iou
best_val_loss = float('inf')
best_iou_score = 0.0

# Inizializzazione dei vettori per il calcolo del dice
num_volumes=7
mean_dice=np.zeros((n_epochs,num_volumes))
num_volumes_val=2
mean_dice_val=np.zeros((n_epochs,num_volumes_val))

# Vettori in cui salvare le loss del train e validation
train_losses = []
val_losses = []

# Definizione dell'epoca di inizio, quando viene caricato un checkpoint è necessario modificarla con l'epoca dell' ultimo salvataggio
epoch=0
# Intervallo di salvataggio dei checkpoint
save_interval = int(0.3 * len(train_loader))

# Impostazione del modello in valutazione per iniziare l'allenamento
model.eval()

'''
# Checkpoint resume
checkpoint_path = os.path.join("/content/drive/MyDrive/Challenge/checkpoints","checkpoint_epoch_5.pth")
checkpoint = torch.load(checkpoint_path)

model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
epoch = checkpoint['epoch']
best_val_loss = checkpoint['best_val_loss']
best_iou_score = checkpoint['best_iou_score']
train_losses = checkpoint['train_losses']
val_losses = checkpoint['val_losses']
epoch=epoch+1
'''

"""**TRAINING**

Si definisce un ciclo di allenamento completo con checkpoint e validazione per ogni epoca. In particolare, gestisce la ricostruzione dei volumi per il calcolo del numero di organoidi e aggiorna le metriche di perdita e IoU durante l'allenamento e la validazione.

*Fase di Training:*

Esegue il forward pass, calcola la perdita e aggiorna i pesi.
Ricostruisce i volumi per il calcolo del numero di organoidi.
Salva checkpoint periodici.
Calcola e stampa il Dice Score volumetrico e l'errore di conteggio organoidi per ogni volume.

*Fase di Validazione:*

Esegue il forward pass sui dati di validazione senza aggiornare i pesi.
Calcola la perdita di validazione e il punteggio IoU.
Calcola e stampa il Dice Score volumetrico e l'errore di conteggio organoidi per ogni volume di validazione.

*Checkpoint e Salvataggio del Modello:*

Salva il modello e aggiorna il miglior punteggio se la perdita di validazione migliora.
Implementa l'early stopping.

*Salvataggio Finale:*

Salva i punteggi Dice medi e le curve di perdita finali.

"""

for epoch in range(epoch, n_epochs):
    # Ad oni epoca si reimposta il modello per lavorare sul train e reimpostata la loss a 0
    model.train()
    running_loss = 0.0
    # Inizializzazione dei volumi degli accumuli
    volumi_pred = [np.zeros((698, 512,512)) for _ in range(num_volumes)]
    volumi_manual = [np.zeros((698, 512,512)) for _ in range(num_volumes)]
    volumi_pred_val = [np.zeros((698, 512,512)) for _ in range(num_volumes_val)]
    volumi_manual_val = [np.zeros((698, 512,512)) for _ in range(num_volumes_val)]

    train_progress_bar = tqdm(train_loader, desc=f"Training Epoch {epoch + 1}/{n_epochs}", unit="batch")

    # Viene ciclato batch per batch il train set
    for batch_idx, (images, masks, filename) in enumerate(train_progress_bar):
        # Le immagini sono trasferite sulla CPU
        images, masks = images.to(device), masks.to(device)
        # Impostazione dei gradienti sull'ottimizzatore e forward pass
        optimizer.zero_grad()
        outputs = model(images).sigmoid().squeeze()

        # Ricostruzione volumi con predizioni e maschere manuali
        [volumi_pred, volumi_manual] = stack_volumi(filename, nomi_volumi_train, volumi_pred, volumi_manual)
        # Valutazione loss
        loss = criterion(outputs, masks)
        # Backward pass
        loss.backward()
        # Aggiornamento pesi
        optimizer.step()
       # Aggiornamento loss
        running_loss += loss.item() * images.size(0)

        # Aggiornamento della progress bar
        train_progress_bar.set_postfix(loss=running_loss / ((train_progress_bar.n + 1) * train_loader.batch_size))
        # Controllo ed eventuale salvataggio nel checkpoint
        if (batch_idx + 1) % save_interval == 0:
            checkpoint_filename = os.path.join(checkpoint_dir, f"checkpoint_epoch_{epoch + 1}_batch_{batch_idx + 1}.pth")
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'best_val_loss': best_val_loss,
                'best_iou_score': best_iou_score,
                'train_losses': train_losses,
                'val_losses': val_losses
            }, checkpoint_filename)
            print(f'Checkpoint saved at epoch {epoch + 1}, batch {batch_idx + 1}')

    # Normalizzazione della loss e salvataggio della variabile loss
    train_loss = running_loss / len(train_loader.dataset)
    train_losses.append(train_loss)

    # Valutazione metrica DSC sui volumi del train
    for i in range(0, num_volumes):
        mean_dice[epoch, i] = calculate_dsc(volumi_manual[i], volumi_pred[i])
        print(f'Dice volumetrico {nomi_volumi_train[i]} at epoch {epoch + 1}, mean_dice= {mean_dice[epoch, i]}')

    # Calcolo errore conteggio training
    for i in range(0,num_volumes):
      labeled_organoids_pred_i, num_organoids_pred[:,i] = count_organoids_3d(volumi_pred[i])
      labeled_organoids_manual_i, num_organoids_manual[:,i] = count_organoids_3d(volumi_manual[i])
      diff[:,i]=abs(num_organoids_manual[:,i]-num_organoids_pred[:,i])
      err[:,i]=diff[:,i]/num_organoids_manual[:,i]*100
      print (f"Errore percentuale conteggio organoidi vol {nomi_volumi_train[i]}:{float(err[0][i]):.4f}")

    # Fase di validazione, si reimposta il modello per la valutazione e vengono reimpostate loss e iou
    model.eval()
    running_loss = 0.0
    running_iou_score = 0.0

   # Stesso ciclo per validation
    val_progress_bar = tqdm(val_loader, desc=f"Validation Epoch {epoch + 1}/{n_epochs}", unit="batch")
    with torch.no_grad():
        for images, masks, filename in val_progress_bar:
            images, masks = images.to(device), masks.to(device)
            outputs = model(images).sigmoid().squeeze()

            [volumi_pred_val, volumi_manual_val] = stack_volumi(filename, nomi_volumi_val, volumi_pred_val, volumi_manual_val)

            loss = criterion(outputs, masks)

            # Aggiornamento loss e IOU score
            running_loss += loss.item() * images.size(0)
            running_iou_score += IOU(outputs, masks).item() * images.size(0)

            val_progress_bar.set_postfix(loss=running_loss / ((val_progress_bar.n + 1) * val_loader.batch_size))

    # Calcolo della validation loss e IOU score
    val_loss = running_loss / len(val_loader.dataset)
    val_losses.append(val_loss)

    # Calcolo dsc sul validation
    for i in range(0, num_volumes_val):
        mean_dice_val[epoch, i] = calculate_dsc(volumi_manual_val[i], volumi_pred_val[i])
        print(f'Dice volumetrico {nomi_volumi_val[i]} at epoch {epoch + 1}, mean_dice= {mean_dice_val[epoch, i]}')
    for i in range(0,num_volumes_val):
      labeled_organoids_pred, num_organoids_pred_val[:,i]= count_organoids_3d(volumi_pred_val[i])
      labeled_organoids_manual, num_organoids_manual_val[:,i]= count_organoids_3d(volumi_manual_val[i])

      diff_val[:,i]=abs(num_organoids_manual_val[:,i]-num_organoids_pred_val[:,i])
      err_val[:,i]=diff[:,i]/num_organoids_manual_val[:,i]*100
      print (f"Errore percentuale conteggio organoidi vol {nomi_volumi_val[i]}:{float(err_val[i]):.4f}")

    # Eventuale salvataggio
    checkpoint_filename = os.path.join(checkpoint_dir, f"checkpoint_epoch_{epoch + 1}.pth")
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'scheduler_state_dict': scheduler.state_dict(),
        'best_val_loss': best_val_loss,
        'best_iou_score': best_iou_score,
        'train_losses': train_losses,
        'val_losses': val_losses
    }, checkpoint_filename)

    print(f'Model checkpoint saved at epoch {epoch + 1}')
    # Plot della funzione di loss
    plt.figure(figsize=(10, 4))
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Val Loss')
    plt.title('Training/Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.tight_layout()
    plt.savefig(os.path.join(loss_dir, f"epoch_{epoch}.png"))
    plt.close()

    # Aggiornamento loss del validation
    scheduler.step(val_loss)

    # Salvataggio del modello se la loss è diminuita
    if val_loss < best_val_loss:
        #  Aggiornamento della validation loss e dell' IOU
        best_val_loss = val_loss
        best_iou_score = running_iou_score / len(val_loader.dataset)
        counter = 0  # Azzeramento il contatore se ho dei miglioramenti

        # Creazione del folder per il salvataggio del modello
        model_dir = os.path.join(working_folder, 'models')
        if not os.path.exists(model_dir):
            os.makedirs(model_dir)

        # Salvataggio modello
        torch.save(model.state_dict(), os.path.join(model_dir, 'final_unet++_bce_loss_nn_local_means.pth'))
        print(f'Model saved at epoch {epoch + 1} with validation loss of {best_val_loss:.4f} and validation IOU of {best_iou_score:.4f}')
    else:
        counter += 1
    #  Criterio early stop ; verifica se si raggiungie il numero massimo di epoche senza miglioramenti
    if counter >= patience:
        print(f"Early stopping: No improvement for {patience} epochs.")
        break
    print(f'Epoch {epoch + 1}/{n_epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation IOU: {best_iou_score:.4f}')

# Salvataggio Dice Score
np.save(os.path.join(working_folder, 'mean_dice_train.npy'), mean_dice)
np.save(os.path.join(working_folder, 'mean_dice_val.npy'), mean_dice_val)

# Plot della loss finale
plt.figure(figsize=(10, 4))
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Val Loss')
plt.title('Training/Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.savefig(os.path.join(loss_dir, "final_plot.png"))
plt.show()

# Visualizzazione dell'output
print(outputs.shape)

"""**VISUALIZZAZIONE RISULTATI**

In questo blocco viene definita la funzione per la visualizzazione della predizione di un certo numero di immagini del test set e dell' immagine originale e maschera manuale corrispondenti.
"""

import matplotlib.pyplot as plt
import torch

threshold_value = 0.5

def visualize_segmentation(test_loader, model, device, num_images=50):
    model.eval()

    with torch.no_grad():
        for i, (images, masks, filename) in enumerate((test_loader)):
            if i >= num_images:
                break

            images, masks = images.to(device), masks.to(device)
            outputs = model(images)

            for j in range(images.size(0)):
                if i * images.size(0) + j >= num_images:
                    break

                plt.figure(figsize=(10, 4))

                plt.subplot(1, 3, 1)
                plt.imshow(images[j, 0].cpu().squeeze(), cmap='gray')
                plt.title('Original Image')

                plt.subplot(1, 3, 2)
                plt.imshow(masks[j].cpu().squeeze(), cmap='gray')
                plt.title('Ground Truth')

                # Applicazione soglia alla softmax
                predicted_mask = (outputs[j].cpu().squeeze() > threshold_value).float()

                plt.subplot(1, 3, 3)
                plt.imshow(predicted_mask, cmap='gray')
                plt.title('Predicted Segmentation')

                plt.tight_layout()
                plt.show()

# Visualizzazione risultati segmentazione
test_loader = DataLoader(test_dataset, BS, shuffle=True)
model = UNet()
model.load_state_dict(torch.load('/content/drive/MyDrive/Challenge/models/model_hist_ADA.pth'))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

visualize_segmentation(test_loader, model, device)